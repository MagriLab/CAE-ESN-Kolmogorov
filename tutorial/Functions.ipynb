{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ESN with bias architecture\n",
    "def step(x_pre, u, sigma_in, rho):\n",
    "    \"\"\" Advances one ESN time step.\n",
    "        Args:\n",
    "            x_pre: reservoir state\n",
    "            u: input\n",
    "        Returns:\n",
    "            new augmented state (new state with bias_out appended)\n",
    "    \"\"\"\n",
    "    # input is normalized and input bias added\n",
    "    u_augmented = np.hstack(((u-u_mean)/norm, bias_in))\n",
    "    # reservoir update\n",
    "    x_post      = np.tanh(Win.dot(u_augmented*sigma_in) + W.dot(rho*x_pre))     \n",
    "    # output bias added\n",
    "    x_augmented = np.concatenate((x_post, bias_out))\n",
    "\n",
    "    return x_augmented\n",
    "\n",
    "def open_loop(U, x0, sigma_in, rho):\n",
    "    \"\"\" Advances ESN in open-loop.\n",
    "        Args:\n",
    "            U: input time series\n",
    "            x0: initial reservoir state\n",
    "        Returns:\n",
    "            time series of augmented reservoir states\n",
    "    \"\"\"\n",
    "    N     = U.shape[0]\n",
    "    Xa    = np.empty((N+1, N_units+1))\n",
    "    Xa[0] = np.concatenate((x0,bias_out))\n",
    "    for i in np.arange(1,N+1):\n",
    "        Xa[i] = step(Xa[i-1,:N_units], U[i-1], sigma_in, rho)\n",
    "\n",
    "    return Xa\n",
    "\n",
    "def closed_loop(N, x0, Wout, sigma_in, rho):\n",
    "    \"\"\" Advances ESN in closed-loop.\n",
    "        Args:\n",
    "            N: number of time steps\n",
    "            x0: initial reservoir state\n",
    "            Wout: output matrix\n",
    "        Returns:\n",
    "            time series of prediction\n",
    "            final augmented reservoir state\n",
    "    \"\"\"\n",
    "    xa    = x0.copy()\n",
    "    Yh    = np.empty((N+1, dim))\n",
    "    Yh[0] = np.dot(xa, Wout)\n",
    "    for i in np.arange(1,N+1):\n",
    "        xa    = step(xa[:N_units], Yh[i-1], sigma_in, rho)\n",
    "        Yh[i] = np.dot(xa, Wout) #np.linalg.multi_dot([xa, Wout]) \n",
    "\n",
    "    return Yh, xa\n",
    "\n",
    "def train_n(U_washout, U_train, Y_train, tikh, sigma_in, rho):\n",
    "    \"\"\" Trains ESN.\n",
    "        Args:\n",
    "            U_washout: washout input time series\n",
    "            U_train: training input time series\n",
    "            tikh: Tikhonov factor\n",
    "        Returns:\n",
    "            time series of augmented reservoir states\n",
    "            optimal output matrix\n",
    "    \"\"\"\n",
    "        \n",
    "    ## initial washout phase\n",
    "    xf = open_loop(U_washout, np.zeros(N_units), sigma_in, rho)[-1,:N_units]\n",
    "    \n",
    "    ## splitting training in N_splits to save memory\n",
    "    LHS = 0\n",
    "    RHS = 0\n",
    "    N_len = (U_train.shape[0]-1)//N_splits\n",
    "    \n",
    "    for ii in range(N_splits):\n",
    "        ## open-loop train phase\n",
    "        t1  = time.time()\n",
    "        Xa1 = open_loop(U_train[ii*N_len:(ii+1)*N_len], xf, sigma_in, rho)[1:]\n",
    "        xf  = Xa1[-1,:N_units].copy()\n",
    "        if ii == 0 and k==0: print('open_loop time:', (time.time()-t1)*N_splits)\n",
    "        \n",
    "        ##computing the matrices for the linear system\n",
    "        t1  = time.time()   \n",
    "        LHS += np.dot(Xa1.T, Xa1) \n",
    "        RHS += np.dot(Xa1.T, Y_train[ii*N_len:(ii+1)*N_len])        \n",
    "        if ii == 0 and k==0: print('matrix multiplication time:', (time.time()-t1)*N_splits)\n",
    "    \n",
    "    # to cover the last part of the data that didn't make it into the even splits\n",
    "    if N_splits > 1:\n",
    "        Xa1 = open_loop(U_train[(ii+1)*N_len:], xf, sigma_in, rho)[1:]\n",
    "        LHS += np.dot(Xa1.T, Xa1) \n",
    "        RHS += np.dot(Xa1.T, Y_train[(ii+1)*N_len:])\n",
    "    \n",
    "    Wout = np.empty((len(tikh),N_units+1,dim))\n",
    "    \n",
    "    # solve linear system for different Tikhonov\n",
    "    for j in range(len(tikh)):\n",
    "        if j == 0: #add tikhonov to the diagonal (fast way that requires less memory)\n",
    "            LHS.ravel()[::LHS.shape[1]+1] += tikh[j]\n",
    "        else:\n",
    "            LHS.ravel()[::LHS.shape[1]+1] += tikh[j] - tikh[j-1]\n",
    "        \n",
    "        #solve linear system\n",
    "        t1  = time.time()\n",
    "        Wout[j] = np.linalg.solve(LHS, RHS)\n",
    "\n",
    "        if j==0 and k==0: print('linear system time:', (time.time() - t1)*len(tikh))\n",
    "\n",
    "    return Wout, LHS, RHS\n",
    "\n",
    "def train_save_n(U_washout, U_train, Y_train, tikh, sigma_in, rho, noise):\n",
    "    \"\"\" Trains ESN.\n",
    "        Args:\n",
    "            U_washout: washout input time series\n",
    "            U_train: training input time series\n",
    "            tikh: Tikhonov factor\n",
    "        Returns:\n",
    "            time series of augmented reservoir states\n",
    "            optimal output matrix\n",
    "    \"\"\"\n",
    "\n",
    "    ## washout phase\n",
    "    xf    = open_loop(U_washout, np.zeros(N_units), sigma_in, rho)[-1,:N_units]\n",
    "    \n",
    "    LHS   = 0\n",
    "    RHS   = 0\n",
    "    N_len = (U_train.shape[0]-1)//N_splits\n",
    "    \n",
    "    for ii in range(N_splits):\n",
    "        t1  = time.time()\n",
    "        ## open-loop train phase\n",
    "        Xa1 = open_loop(U_train[ii*N_len:(ii+1)*N_len], xf, sigma_in, rho)[1:]\n",
    "        xf  = Xa1[-1,:N_units].copy()\n",
    "\n",
    "        t1  = time.time()   \n",
    "        LHS += np.dot(Xa1.T, Xa1) \n",
    "        RHS += np.dot(Xa1.T, Y_train[ii*N_len:(ii+1)*N_len])\n",
    "                    \n",
    "    if N_splits > 1:# to cover the last part of the data that didn't make into the even splits\n",
    "        Xa1 = open_loop(U_train[(ii+1)*N_len:], xf, sigma_in, rho)[1:]\n",
    "        LHS += np.dot(Xa1.T, Xa1) \n",
    "        RHS += np.dot(Xa1.T, Y_train[(ii+1)*N_len:])\n",
    "\n",
    "    LHS.ravel()[::LHS.shape[1]+1] += tikh\n",
    "    \n",
    "    Wout = np.linalg.solve(LHS, RHS)\n",
    "    \n",
    "    return Wout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objective Functions to minimize with Bayesian Optimization\n",
    "\n",
    "def KFC_Noise(x):\n",
    "    #K-fold cross Validation\n",
    "    \n",
    "    global tikh_opt, k, ti\n",
    "    \n",
    "    #setting and initializing\n",
    "    rho      = x[0]\n",
    "    sigma_in = 10**x[1]\n",
    "    ti       = time.time()\n",
    "    lenn     = tikh.size\n",
    "    Mean     = np.zeros(lenn)\n",
    "    \n",
    "    #Train using tv: training+val\n",
    "    Wout, LHS0, RHS0 = train_n(U_washout, U_tv, Y_tv, tikh, sigma_in, rho)\n",
    "        \n",
    "    #Different Folds in the validation set\n",
    "    t1   = time.time()\n",
    "    for i in range(N_fo):\n",
    "\n",
    "       #select washout and validation\n",
    "        p      = N_in + i*N_fw\n",
    "        Y_val  = U[N_washout + p    : N_washout + p + N_val    ].copy()\n",
    "        U_wash = U[            p    : N_washout + p            ].copy()\n",
    "        \n",
    "        #washout\n",
    "        xf     = open_loop(U_wash, np.zeros(N_units), sigma_in, rho)[-1]\n",
    "        #Train: remove the validation interval\n",
    "        Xt     = open_loop(Y_val, xf[:N_units], sigma_in, rho)[:-1]\n",
    "        \n",
    "        LHS    = LHS0 - np.dot(Xt.T, Xt)\n",
    "        RHS    = RHS0 - np.dot(Xt.T, Y_val)\n",
    "\n",
    "        for j in range(lenn):\n",
    "            if j == 0: #add tikhonov to the diagonal (fast way that requires less memory)\n",
    "                LHS.ravel()[::LHS.shape[1]+1] += tikh[j]\n",
    "            else:\n",
    "                LHS.ravel()[::LHS.shape[1]+1] += tikh[j] - tikh[j-1]\n",
    "            \n",
    "            Wout[j]  = np.linalg.solve(LHS, RHS)\n",
    "\n",
    "            #Validate\n",
    "            Yh_val   = closed_loop(N_val-1, xf, Wout[j], sigma_in, rho)[0]\n",
    "            Mean[j] += np.log10(np.mean((Y_val-Yh_val)**2))\n",
    "        \n",
    "                \n",
    "    if k==0: print('closed-loop time:', time.time() - t1)\n",
    "    \n",
    "    #select optimal tikh\n",
    "    a           = np.argmin(Mean)\n",
    "    tikh_opt[k] = tikh[a]\n",
    "    k          +=1\n",
    "    \n",
    "    #print every set of hyperparameters\n",
    "    if print_flag:\n",
    "        print(k, ': Spectral radius, Input Scaling, Tikhonov, MSE:',\n",
    "              rho, sigma_in, tikh_opt[k-1],  Mean[a]/N_fo)\n",
    "\n",
    "    return Mean[a]/N_fo\n",
    "\n",
    "def RVC_Noise(x):\n",
    "    #Recycle Validation\n",
    "    \n",
    "    global tikh_opt, k, ti\n",
    "    \n",
    "    #setting and initializing\n",
    "    rho      = x[0]\n",
    "    sigma_in = 10**x[1]\n",
    "    ti       = time.time()\n",
    "    lenn     = tikh.size\n",
    "    Mean     = np.zeros(lenn)\n",
    "    \n",
    "    #Train using tv: training+val\n",
    "    Wout = train_n(U_washout, U_tv, Y_tv, tikh, sigma_in, rho)[0]\n",
    "\n",
    "    #Different Folds in the validation set\n",
    "    t1   = time.time()\n",
    "    for i in range(N_fo):\n",
    "        \n",
    "        #select washout and validation\n",
    "        p      = N_in + i*N_fw\n",
    "        Y_val  = U[N_washout + p : N_washout + p + N_val].copy()\n",
    "        U_wash = U[            p : N_washout + p        ].copy()\n",
    "        \n",
    "        #washout before closed loop\n",
    "        xf = open_loop(U_wash, np.zeros(N_units), sigma_in, rho)[-1]\n",
    "                  \n",
    "        for j in range(lenn):\n",
    "            #Validate\n",
    "            Yh_val   = closed_loop(N_val-1, xf, Wout[j], sigma_in, rho)[0]\n",
    "            Mean[j] += np.log10(np.mean((Y_val-Yh_val)**2))\n",
    "                            \n",
    "    if k==0: print('closed-loop time:', time.time() - t1)\n",
    "    \n",
    "    #select optimal tikh\n",
    "    a           = np.argmin(Mean)\n",
    "    tikh_opt[k] = tikh[a]\n",
    "    k          +=1\n",
    "    \n",
    "    #print for every set of hyperparameters\n",
    "    if print_flag:\n",
    "        print(k, ': Spectral radius, Input Scaling, Tikhonov, MSE:',\n",
    "              rho, sigma_in, tikh_opt[k-1],  Mean[a]/N_fo)\n",
    "\n",
    "    return Mean[a]/N_fo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
